# Instru√ß√µes Detalhadas - Tema B no GitHub Codespaces

Este documento fornece instru√ß√µes passo a passo para executar o Tema B no GitHub Codespaces e comparar os resultados com os apresentados no relat√≥rio.

## üìã √çndice

1. [Pr√©-requisitos](#pr√©-requisitos)
2. [Configura√ß√£o Inicial](#configura√ß√£o-inicial)
3. [Execu√ß√£o no GitHub Codespaces](#execu√ß√£o-no-github-codespaces)
4. [Execu√ß√£o Local com Docker](#execu√ß√£o-local-com-docker)
5. [Interpreta√ß√£o dos Resultados](#interpreta√ß√£o-dos-resultados)
6. [Compara√ß√£o com Resultados Apresentados](#compara√ß√£o-com-resultados-apresentados)
7. [Troubleshooting](#troubleshooting)

---

## 1. Pr√©-requisitos

### Para GitHub Codespaces:
- Conta no GitHub
- Acesso ao GitHub Codespaces (inclu√≠do em contas gratuitas com limite mensal)

### Para Execu√ß√£o Local:
- Docker Desktop instalado (Windows/Mac) ou Docker Engine (Linux)
- Docker Compose instalado
- M√≠nimo de 8GB de RAM dispon√≠vel
- 10GB de espa√ßo em disco livre

---

## 2. Configura√ß√£o Inicial

### 2.1. Fork ou Clone do Reposit√≥rio

**Op√ß√£o A: Fork (Recomendado)**
1. Acesse o reposit√≥rio no GitHub
2. Clique no bot√£o **"Fork"** no canto superior direito
3. Aguarde a cria√ß√£o do fork na sua conta

**Op√ß√£o B: Clone Local**
```bash
git clone https://github.com/SEU_USUARIO/tema-b-otimizacao.git
cd tema-b-otimizacao
```

---

## 3. Execu√ß√£o no GitHub Codespaces

### 3.1. Criar Codespace

1. No reposit√≥rio (fork ou original), clique no bot√£o verde **"Code"**
2. Selecione a aba **"Codespaces"**
3. Clique em **"Create codespace on main"**
4. Aguarde a cria√ß√£o do ambiente (pode levar 2-5 minutos)

### 3.2. Verificar Ambiente

Ap√≥s a cria√ß√£o do Codespace, voc√™ ver√° um VS Code no navegador. Verifique se o ambiente est√° pronto:

```bash
# Verificar vers√£o do Python
python3 --version
# Esperado: Python 3.11.x

# Verificar vers√£o do Java
java -version
# Esperado: OpenJDK 11.x

# Verificar instala√ß√£o do Spark
ls -la /opt/spark
# Esperado: Diret√≥rio com arquivos do Spark 3.5.0
```

### 3.3. Dataset Pr√©-Gerado

Este projeto inclui um dataset pr√©-gerado de 1 milh√£o de registros em `data/tema_b_sensores_iot.csv`.

**Vantagens:**
- Execu√ß√£o mais r√°pida (~3-5 minutos vs ~10 minutos)
- Resultados consistentes e reproduz√≠veis
- Facilita valida√ß√£o pelo avaliador

**Detalhes do Dataset:**
- Veja `data/DATASET_INFO.md` para documenta√ß√£o completa
- 1.000.000 registros de sensores IoT
- 10 colunas (sensor_id, sensor_type, location, city, timestamp, value, unit, battery_level, signal_strength, status)
- Tamanho: ~87 MB

### 3.3. Executar a An√°lise

**M√©todo 1: Script Automatizado (Recomendado)**

```bash
# Dar permiss√£o de execu√ß√£o ao script
chmod +x run.sh

# Executar pipeline completo
./run.sh full
```

**M√©todo 2: Execu√ß√£o Manual**

```bash
# Construir imagem Docker
docker-compose build

# Iniciar container
docker-compose up -d

# Aguardar 5 segundos para Spark inicializar
sleep 5

# Executar an√°lise
docker-compose exec spark-tema-b python3 /app/scripts/tema_b_otimizacao_docker.py
```

### 3.4. Acompanhar Execu√ß√£o

A execu√ß√£o completa leva aproximadamente **5-10 minutos** dependendo dos recursos do Codespace.

Voc√™ ver√° no console:
1. ‚úì Iniciando Spark Session
2. ‚úì Gerando dataset (1.000.000 registros)
3. ‚úì Salvando em CSV, JSON, Parquet, ORC
4. ‚úì Analisando performance de cada formato
5. ‚úì Gerando relat√≥rio comparativo

### 3.5. Verificar Resultados

```bash
# Listar arquivos gerados
ls -lh /app/data/
ls -lh /app/output/

# Visualizar relat√≥rio JSON
cat /app/output/relatorio_comparativo.json

# Visualizar tamanhos dos arquivos
du -sh /app/data/*
```

---

## 4. Execu√ß√£o Local com Docker

### 4.1. Preparar Ambiente

```bash
# Navegar at√© o diret√≥rio do projeto
cd tema-b-otimizacao

# Verificar se Docker est√° rodando
docker --version
docker-compose --version
```

### 4.2. Executar Pipeline

**Op√ß√£o A: Script Automatizado**

```bash
./run.sh full
```

**Op√ß√£o B: Comandos Manuais**

```bash
# 1. Construir imagem
docker-compose build

# 2. Iniciar container
docker-compose up -d

# 3. Executar an√°lise
docker-compose exec spark-tema-b python3 /app/scripts/tema_b_otimizacao_docker.py

# 4. Verificar resultados
docker-compose exec spark-tema-b ls -lh /app/data/
docker-compose exec spark-tema-b cat /app/output/relatorio_comparativo.json

# 5. Parar container
docker-compose down
```

### 4.3. Acessar Shell do Container (Opcional)

```bash
# Abrir shell interativo
./run.sh shell

# Ou manualmente:
docker-compose exec spark-tema-b /bin/bash

# Dentro do container, voc√™ pode:
# - Explorar os dados gerados
# - Executar queries personalizadas
# - Verificar logs do Spark
```

---

## 5. Interpreta√ß√£o dos Resultados

### 5.1. Estrutura do Relat√≥rio

O arquivo `output/relatorio_comparativo.json` cont√©m:

```json
{
  "CSV": {
    "read_time": 45.2,
    "filter_time": 38.1,
    "select_time": 12.3,
    "agg_time": 35.4,
    "size_mb": 87.5
  },
  "JSON": { ... },
  "Parquet": { ... },
  "ORC": { ... }
}
```

### 5.2. M√©tricas Importantes

- **size_mb:** Tamanho total em disco (MB)
- **read_time:** Tempo de leitura completa (segundos)
- **filter_time:** Tempo de query com filtro WHERE (segundos)
- **select_time:** Tempo de sele√ß√£o de colunas (segundos)
- **agg_time:** Tempo de agrega√ß√£o GROUP BY (segundos)

### 5.3. Console Output

O console exibir√° tabelas comparativas:

```
TAMANHO EM DISCO:
--------------------------------------------------------------------------------
Formato         Tamanho (MB)    Redu√ß√£o vs CSV
--------------------------------------------------------------------------------
CSV             87.50                    0.0%
JSON            120.30                  -37.5%
Parquet         25.20                   71.2%
ORC             22.10                   74.7%

PERFORMANCE DE LEITURA:
--------------------------------------------------------------------------------
Formato         Leitura (s)     Filtro (s)      Agrega√ß√£o (s)
--------------------------------------------------------------------------------
CSV             45.20           38.10           35.40
JSON            52.30           42.50           39.80
Parquet         12.10           7.20            9.10
ORC             11.30           6.80            8.50
```

---

## 6. Compara√ß√£o com Resultados Apresentados

### 6.1. Resultados Esperados (Relat√≥rio Original)

| Formato | Tamanho (MB) | Redu√ß√£o | Leitura (s) | Filtro (s) |
|---------|--------------|---------|-------------|------------|
| CSV     | ~87          | 0%      | ~45         | ~38        |
| JSON    | ~120         | -38%    | ~52         | ~42        |
| Parquet | ~25          | 71%     | ~12         | ~7         |
| ORC     | ~22          | 75%     | ~11         | ~7         |

### 6.2. Toler√¢ncia de Varia√ß√£o

Os resultados podem variar em **¬±10-15%** devido a:
- Recursos de CPU/RAM do ambiente
- Carga do sistema
- Vers√£o exata do Spark
- Otimiza√ß√µes de JVM

**Exemplo de varia√ß√£o aceit√°vel:**
- CSV: 80-95 MB (esperado: ~87 MB)
- Parquet: 22-28 MB (esperado: ~25 MB)
- Leitura CSV: 40-50s (esperado: ~45s)

### 6.3. Valida√ß√£o dos Resultados

Para validar que a execu√ß√£o foi bem-sucedida, verifique:

1. **Tamanhos Relativos:**
   - Parquet deve ser ~70% menor que CSV
   - ORC deve ser ~75% menor que CSV
   - JSON deve ser ~35% maior que CSV

2. **Performance Relativa:**
   - Parquet/ORC devem ser ~3-4x mais r√°pidos na leitura
   - Parquet/ORC devem ser ~5-6x mais r√°pidos em queries com filtro

3. **Conclus√µes:**
   - Formatos colunares (Parquet/ORC) devem ser superiores em todos os aspectos
   - JSON deve ser o pior em tamanho e performance

---

## 7. Troubleshooting

### 7.1. Erro: "Docker not found"

**Solu√ß√£o:**
- GitHub Codespaces: Docker j√° est√° pr√©-instalado. Recarregue a p√°gina.
- Local: Instale o Docker Desktop ou Docker Engine.

### 7.2. Erro: "Out of memory"

**Solu√ß√£o:**
```bash
# Editar docker-compose.yml e reduzir mem√≥ria:
deploy:
  resources:
    limits:
      memory: 4G  # Reduzir de 8G para 4G
```

### 7.3. Erro: "Permission denied"

**Solu√ß√£o:**
```bash
# Dar permiss√£o de execu√ß√£o aos scripts
chmod +x run.sh
chmod +x scripts/*.py
```

### 7.4. Execu√ß√£o Muito Lenta

**Solu√ß√£o:**
- Reduzir n√∫mero de registros no script:
  ```python
  NUM_RECORDS = 100_000  # Ao inv√©s de 1_000_000
  ```

### 7.5. Container n√£o Inicia

**Solu√ß√£o:**
```bash
# Verificar logs
docker-compose logs

# Reconstruir imagem
docker-compose down
docker-compose build --no-cache
docker-compose up -d
```

---

## 8. Comandos √öteis

```bash
# Ver logs em tempo real
docker-compose logs -f

# Parar tudo
docker-compose down

# Limpar volumes e recome√ßar
docker-compose down -v
rm -rf data/* output/*

# Verificar uso de recursos
docker stats

# Listar containers rodando
docker ps

# Abrir Spark UI (se dispon√≠vel)
# Acesse: http://localhost:8080
```

---

## 9. Pr√≥ximos Passos

Ap√≥s executar com sucesso:

1. **Explorar os Dados:**
   - Abra os arquivos gerados em `data/`
   - Compare visualmente os tamanhos

2. **Personalizar a An√°lise:**
   - Modifique `NUM_RECORDS` para testar com datasets maiores/menores
   - Adicione novos formatos ou compress√µes

3. **Criar Visualiza√ß√µes:**
   - Use os dados do relat√≥rio JSON para criar gr√°ficos
   - Gere apresenta√ß√µes com os resultados

4. **Documentar Aprendizados:**
   - Anote as diferen√ßas observadas
   - Compare com a teoria dos materiais de aula

---

## 10. Suporte

Para d√∫vidas ou problemas:

1. Verifique a se√ß√£o de [Troubleshooting](#troubleshooting)
2. Consulte os logs: `docker-compose logs`
3. Revise o c√≥digo em `scripts/tema_b_otimizacao_docker.py`
4. Abra uma issue no reposit√≥rio GitHub

---

**Bom trabalho! üöÄ**
